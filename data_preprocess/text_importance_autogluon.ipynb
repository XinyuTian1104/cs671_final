{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.0' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:62: UserWarning: Pandas requires version '1.3.4' or newer of 'bottleneck' (version '1.3.2' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20231203_061120\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20231203_061120\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.0.0\n",
      "Python Version:     3.9.7\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   Darwin Kernel Version 23.1.0: Mon Oct  9 21:27:24 PDT 2023; root:xnu-10002.41.9~6/RELEASE_ARM64_T6000\n",
      "CPU Count:          10\n",
      "Memory Avail:       4.35 GB / 32.00 GB (13.6%)\n",
      "Disk Space Avail:   370.67 GB / 926.35 GB (40.0%)\n",
      "===================================================\n",
      "Train Data Rows:    12352\n",
      "Train Data Columns: 10\n",
      "Label Column:       price\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == float, but few unique label-values observed and label-values can be converted to int).\n",
      "\t6 unique label values:  [5.0, 1.0, 2.0, 3.0, 0.0, 4.0]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 6\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    4482.05 MB\n",
      "\tTrain Data (Original)  Memory Usage: 28.50 MB (0.6% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['name', 'description', 'property_type', 'amenities']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 10000\n",
      "\t\tWarning: Due to memory constraints, ngram feature count is being reduced. Allocate more memory to maximize model quality.\n",
      "\t\tReducing Vectorizer vocab size from 10000 to 5389 to avoid OOM error\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])          : 1 | ['id']\n",
      "\t\t('object', [])       : 5 | ['host_verifications', 'neighbourhood_cleansed', 'neighbourhood_group_cleansed', 'room_type', 'bathrooms_text']\n",
      "\t\t('object', ['text']) : 4 | ['name', 'description', 'property_type', 'amenities']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :    5 | ['host_verifications', 'neighbourhood_cleansed', 'neighbourhood_group_cleansed', 'room_type', 'bathrooms_text']\n",
      "\t\t('category', ['text_as_category'])  :    4 | ['name', 'description', 'property_type', 'amenities']\n",
      "\t\t('int', [])                         :    1 | ['id']\n",
      "\t\t('int', ['binned', 'text_special']) :   62 | ['name.char_count', 'name.word_count', 'name.capital_ratio', 'name.lower_ratio', 'name.digit_ratio', ...]\n",
      "\t\t('int', ['text_ngram'])             : 4530 | ['__nlp__.000', '__nlp__.10', '__nlp__.10 min', '__nlp__.10 minute', '__nlp__.10 minutes', ...]\n",
      "\t52.7s = Fit runtime\n",
      "\t10 features in original data used to generate 4602 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 107.71 MB (2.4% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 53.2s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 11116, Val Rows: 1236\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\tWarning: Potentially not enough memory to safely train model. Estimated to require 0.737 GB out of 4.561 GB available memory (16.151%)... (20.000% of avail memory is the max safe size)\n",
      "\tTo avoid this warning, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=1.13 to avoid the warning)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\t\tSetting \"ag.max_memory_usage_ratio\" to values above 1 may result in out-of-memory errors. You may consider using a machine with more memory as a safer alternative.\n",
      "\tWarning: Exception caused KNeighborsUnif to fail during training... Skipping this model.\n",
      "\t\t'NoneType' object has no attribute 'split'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1839, in _train_and_save\n",
      "    y_pred_proba_val = model.predict_proba(X_val)\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 949, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, **kwargs)\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 991, in _predict_proba\n",
      "    y_pred_proba = self.model.predict_proba(X)\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py\", line 355, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_base.py\", line 822, in kneighbors\n",
      "    results = ArgKmin.compute(\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 271, in compute\n",
      "    return ArgKmin32.compute(\n",
      "  File \"sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx\", line 575, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin32.compute\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py\", line 74, in threadpool_limits\n",
      "    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/threadpoolctl.py\", line 171, in __init__\n",
      "    self._original_info = self._set_threadpool_limits()\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/threadpoolctl.py\", line 268, in _set_threadpool_limits\n",
      "    modules = _ThreadpoolInfo(prefixes=self._prefixes,\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/threadpoolctl.py\", line 340, in __init__\n",
      "    self._load_modules()\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/threadpoolctl.py\", line 371, in _load_modules\n",
      "    self._find_modules_with_dyld()\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/threadpoolctl.py\", line 428, in _find_modules_with_dyld\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n",
      "Fitting model: KNeighborsDist ...\n",
      "\tWarning: Potentially not enough memory to safely train model. Estimated to require 0.737 GB out of 4.478 GB available memory (16.452%)... (20.000% of avail memory is the max safe size)\n",
      "\tTo avoid this warning, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=1.15 to avoid the warning)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\t\tSetting \"ag.max_memory_usage_ratio\" to values above 1 may result in out-of-memory errors. You may consider using a machine with more memory as a safer alternative.\n",
      "\tWarning: Exception caused KNeighborsDist to fail during training... Skipping this model.\n",
      "\t\t'NoneType' object has no attribute 'split'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1839, in _train_and_save\n",
      "    y_pred_proba_val = model.predict_proba(X_val)\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 949, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, **kwargs)\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 991, in _predict_proba\n",
      "    y_pred_proba = self.model.predict_proba(X)\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py\", line 358, in predict_proba\n",
      "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_base.py\", line 822, in kneighbors\n",
      "    results = ArgKmin.compute(\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 271, in compute\n",
      "    return ArgKmin32.compute(\n",
      "  File \"sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx\", line 575, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin32.compute\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py\", line 74, in threadpool_limits\n",
      "    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/threadpoolctl.py\", line 171, in __init__\n",
      "    self._original_info = self._set_threadpool_limits()\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/threadpoolctl.py\", line 268, in _set_threadpool_limits\n",
      "    modules = _ThreadpoolInfo(prefixes=self._prefixes,\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/threadpoolctl.py\", line 340, in __init__\n",
      "    self._load_modules()\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/threadpoolctl.py\", line 371, in _load_modules\n",
      "    self._find_modules_with_dyld()\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/threadpoolctl.py\", line 428, in _find_modules_with_dyld\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "No improvement since epoch 9: early stopping\n",
      "\t0.4984\t = Validation score   (accuracy)\n",
      "\t10.9s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\tWarning: Exception caused LightGBMXT to fail during training... Skipping this model.\n",
      "\t\tmodule 'pandas.core.strings' has no attribute 'StringMethods'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1817, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1763, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 854, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 98, in _fit\n",
      "    try_import_lightgbm()  # raise helpful error message if LightGBM isn't installed\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/autogluon/common/utils/try_import.py\", line 82, in try_import_lightgbm\n",
      "    import lightgbm\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/lightgbm/__init__.py\", line 8, in <module>\n",
      "    from .basic import Booster, Dataset, Sequence, register_logger\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 21, in <module>\n",
      "    from .compat import PANDAS_INSTALLED, concat, dt_DataTable, pd_CategoricalDtype, pd_DataFrame, pd_Series\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/lightgbm/compat.py\", line 145, in <module>\n",
      "    from dask.dataframe import DataFrame as dask_DataFrame\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/dask/dataframe/__init__.py\", line 3, in <module>\n",
      "    from . import backends, dispatch, rolling\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/dask/dataframe/backends.py\", line 20, in <module>\n",
      "    from .core import DataFrame, Index, Scalar, Series, _Frame\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/dask/dataframe/core.py\", line 52, in <module>\n",
      "    from .accessor import DatetimeAccessor, StringAccessor\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/dask/dataframe/accessor.py\", line 109, in <module>\n",
      "    class StringAccessor(Accessor):\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/dask/dataframe/accessor.py\", line 121, in StringAccessor\n",
      "    @derived_from(pd.core.strings.StringMethods)\n",
      "AttributeError: module 'pandas.core.strings' has no attribute 'StringMethods'\n",
      "Fitting model: LightGBM ...\n",
      "\tWarning: Exception caused LightGBM to fail during training... Skipping this model.\n",
      "\t\tmodule 'pandas.core.strings' has no attribute 'StringMethods'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1817, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1763, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 854, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 98, in _fit\n",
      "    try_import_lightgbm()  # raise helpful error message if LightGBM isn't installed\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/autogluon/common/utils/try_import.py\", line 82, in try_import_lightgbm\n",
      "    import lightgbm\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/lightgbm/__init__.py\", line 8, in <module>\n",
      "    from .basic import Booster, Dataset, Sequence, register_logger\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 21, in <module>\n",
      "    from .compat import PANDAS_INSTALLED, concat, dt_DataTable, pd_CategoricalDtype, pd_DataFrame, pd_Series\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/lightgbm/compat.py\", line 145, in <module>\n",
      "    from dask.dataframe import DataFrame as dask_DataFrame\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/dask/dataframe/__init__.py\", line 3, in <module>\n",
      "    from . import backends, dispatch, rolling\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/dask/dataframe/backends.py\", line 20, in <module>\n",
      "    from .core import DataFrame, Index, Scalar, Series, _Frame\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/dask/dataframe/core.py\", line 52, in <module>\n",
      "    from .accessor import DatetimeAccessor, StringAccessor\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/dask/dataframe/accessor.py\", line 109, in <module>\n",
      "    class StringAccessor(Accessor):\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/dask/dataframe/accessor.py\", line 121, in StringAccessor\n",
      "    @derived_from(pd.core.strings.StringMethods)\n",
      "AttributeError: module 'pandas.core.strings' has no attribute 'StringMethods'\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.5316\t = Validation score   (accuracy)\n",
      "\t6.48s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.5413\t = Validation score   (accuracy)\n",
      "\t6.26s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\tMany features detected (4602), dynamically setting 'colsample_bylevel' to 0.21729682746631898 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\t0.5518\t = Validation score   (accuracy)\n",
      "\t143.43s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.5283\t = Validation score   (accuracy)\n",
      "\t6.36s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.5243\t = Validation score   (accuracy)\n",
      "\t5.9s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.5566\t = Validation score   (accuracy)\n",
      "\t46.18s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.521\t = Validation score   (accuracy)\n",
      "\t18.32s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\tWarning: Not enough memory to safely train model. Estimated to require 4.266 GB out of 4.153 GB available memory (102.734%)... (90.000% of avail memory is the max safe size)\n",
      "\tTo force training the model, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=1.19 to avoid the error)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\t\tSetting \"ag.max_memory_usage_ratio\" to values above 1 may result in out-of-memory errors. You may consider using a machine with more memory as a safer alternative.\n",
      "\tNot enough memory to train LightGBMLarge... Skipping this model.\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'CatBoost': 0.308, 'ExtraTreesEntr': 0.231, 'XGBoost': 0.231, 'NeuralNetTorch': 0.231}\n",
      "\t0.5696\t = Validation score   (accuracy)\n",
      "\t0.28s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 311.15s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20231203_061120\")\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "use_data = data[['id', \n",
    "                      'name', \n",
    "                      'description', \n",
    "                      'host_verifications', \n",
    "                      'neighbourhood_cleansed', \n",
    "                      'neighbourhood_group_cleansed',\n",
    "                      'property_type',\n",
    "                      'room_type',\n",
    "                      'bathrooms_text',\n",
    "                      'amenities',\n",
    "                      'price']]\n",
    "\n",
    "train_data, test_data = train_test_split(use_data, test_size=0.2, random_state=42)\n",
    "train_data = TabularDataset(train_data) \n",
    "test_data = TabularDataset(test_data)\n",
    "\n",
    "predictor = TabularPredictor(label='price').fit(train_data=train_data)\n",
    "predictions = predictor.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the best model to predict based on test.csv \n",
    "pred_data = pd.read_csv('test.csv')\n",
    "pred_data = pred_data[['id', \n",
    "                      'name', \n",
    "                      'description', \n",
    "                      'host_verifications', \n",
    "                      'neighbourhood_cleansed', \n",
    "                      'neighbourhood_group_cleansed',\n",
    "                      'property_type',\n",
    "                      'room_type',\n",
    "                      'bathrooms_text',\n",
    "                      'amenities']]\n",
    "pred_data = TabularDataset(pred_data)\n",
    "predictions = predictor.predict(pred_data)\n",
    "\n",
    "# save the predictions to a csv file that only contains the id and the price columns\n",
    "predictions.to_csv('submission.csv', index=False)\n",
    "# add an ID column to the predictions\n",
    "submission = pd.read_csv('submission.csv')\n",
    "submission.insert(0, 'id', range(0, len(submission)))\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.560052</td>\n",
       "      <td>0.569579</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.852850</td>\n",
       "      <td>0.324258</td>\n",
       "      <td>214.108756</td>\n",
       "      <td>0.001869</td>\n",
       "      <td>0.000447</td>\n",
       "      <td>0.283991</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.549045</td>\n",
       "      <td>0.551780</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.235078</td>\n",
       "      <td>0.124845</td>\n",
       "      <td>143.429339</td>\n",
       "      <td>0.235078</td>\n",
       "      <td>0.124845</td>\n",
       "      <td>143.429339</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.549045</td>\n",
       "      <td>0.556634</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.350018</td>\n",
       "      <td>0.104317</td>\n",
       "      <td>46.178284</td>\n",
       "      <td>0.350018</td>\n",
       "      <td>0.104317</td>\n",
       "      <td>46.178284</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestGini</td>\n",
       "      <td>0.531887</td>\n",
       "      <td>0.531553</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.188234</td>\n",
       "      <td>0.072511</td>\n",
       "      <td>6.478947</td>\n",
       "      <td>0.188234</td>\n",
       "      <td>0.072511</td>\n",
       "      <td>6.478947</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestEntr</td>\n",
       "      <td>0.522499</td>\n",
       "      <td>0.541262</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.173235</td>\n",
       "      <td>0.072896</td>\n",
       "      <td>6.264850</td>\n",
       "      <td>0.173235</td>\n",
       "      <td>0.072896</td>\n",
       "      <td>6.264850</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ExtraTreesGini</td>\n",
       "      <td>0.521204</td>\n",
       "      <td>0.528317</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.154161</td>\n",
       "      <td>0.071558</td>\n",
       "      <td>6.359418</td>\n",
       "      <td>0.154161</td>\n",
       "      <td>0.071558</td>\n",
       "      <td>6.359418</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ExtraTreesEntr</td>\n",
       "      <td>0.516025</td>\n",
       "      <td>0.524272</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.212898</td>\n",
       "      <td>0.072794</td>\n",
       "      <td>5.896620</td>\n",
       "      <td>0.212898</td>\n",
       "      <td>0.072794</td>\n",
       "      <td>5.896620</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NeuralNetFastAI</td>\n",
       "      <td>0.501457</td>\n",
       "      <td>0.498382</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.041937</td>\n",
       "      <td>0.018176</td>\n",
       "      <td>10.899491</td>\n",
       "      <td>0.041937</td>\n",
       "      <td>0.018176</td>\n",
       "      <td>10.899491</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NeuralNetTorch</td>\n",
       "      <td>0.500809</td>\n",
       "      <td>0.521036</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.052987</td>\n",
       "      <td>0.021855</td>\n",
       "      <td>18.320521</td>\n",
       "      <td>0.052987</td>\n",
       "      <td>0.021855</td>\n",
       "      <td>18.320521</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  score_test  score_val eval_metric  pred_time_test  \\\n",
       "0  WeightedEnsemble_L2    0.560052   0.569579    accuracy        0.852850   \n",
       "1             CatBoost    0.549045   0.551780    accuracy        0.235078   \n",
       "2              XGBoost    0.549045   0.556634    accuracy        0.350018   \n",
       "3     RandomForestGini    0.531887   0.531553    accuracy        0.188234   \n",
       "4     RandomForestEntr    0.522499   0.541262    accuracy        0.173235   \n",
       "5       ExtraTreesGini    0.521204   0.528317    accuracy        0.154161   \n",
       "6       ExtraTreesEntr    0.516025   0.524272    accuracy        0.212898   \n",
       "7      NeuralNetFastAI    0.501457   0.498382    accuracy        0.041937   \n",
       "8       NeuralNetTorch    0.500809   0.521036    accuracy        0.052987   \n",
       "\n",
       "   pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
       "0       0.324258  214.108756                 0.001869                0.000447   \n",
       "1       0.124845  143.429339                 0.235078                0.124845   \n",
       "2       0.104317   46.178284                 0.350018                0.104317   \n",
       "3       0.072511    6.478947                 0.188234                0.072511   \n",
       "4       0.072896    6.264850                 0.173235                0.072896   \n",
       "5       0.071558    6.359418                 0.154161                0.071558   \n",
       "6       0.072794    5.896620                 0.212898                0.072794   \n",
       "7       0.018176   10.899491                 0.041937                0.018176   \n",
       "8       0.021855   18.320521                 0.052987                0.021855   \n",
       "\n",
       "   fit_time_marginal  stack_level  can_infer  fit_order  \n",
       "0           0.283991            2       True          9  \n",
       "1         143.429339            1       True          4  \n",
       "2          46.178284            1       True          7  \n",
       "3           6.478947            1       True          2  \n",
       "4           6.264850            1       True          3  \n",
       "5           6.359418            1       True          5  \n",
       "6           5.896620            1       True          6  \n",
       "7          10.899491            1       True          1  \n",
       "8          18.320521            1       True          8  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(test_data, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing feature importance via permutation shuffling for 10 features using 3089 rows with 5 shuffle sets...\n",
      "\t127.9s\t= Expected runtime (25.58s per shuffle set)\n",
      "\t107.13s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>stddev</th>\n",
       "      <th>p_value</th>\n",
       "      <th>n</th>\n",
       "      <th>p99_high</th>\n",
       "      <th>p99_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>description</th>\n",
       "      <td>0.057559</td>\n",
       "      <td>0.006850</td>\n",
       "      <td>2.361957e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.071663</td>\n",
       "      <td>0.043455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <td>0.055422</td>\n",
       "      <td>0.005438</td>\n",
       "      <td>1.098311e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.066620</td>\n",
       "      <td>0.044225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amenities</th>\n",
       "      <td>0.055422</td>\n",
       "      <td>0.002236</td>\n",
       "      <td>3.171474e-07</td>\n",
       "      <td>5</td>\n",
       "      <td>0.060026</td>\n",
       "      <td>0.050819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bathrooms_text</th>\n",
       "      <td>0.051602</td>\n",
       "      <td>0.005492</td>\n",
       "      <td>1.516627e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.062910</td>\n",
       "      <td>0.040294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>property_type</th>\n",
       "      <td>0.038459</td>\n",
       "      <td>0.003375</td>\n",
       "      <td>7.045760e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.045409</td>\n",
       "      <td>0.031510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed</th>\n",
       "      <td>0.032373</td>\n",
       "      <td>0.004270</td>\n",
       "      <td>3.550346e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.041166</td>\n",
       "      <td>0.023580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>room_type</th>\n",
       "      <td>0.002007</td>\n",
       "      <td>0.001625</td>\n",
       "      <td>2.538052e-02</td>\n",
       "      <td>5</td>\n",
       "      <td>0.005353</td>\n",
       "      <td>-0.001339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_verifications</th>\n",
       "      <td>0.000842</td>\n",
       "      <td>0.002130</td>\n",
       "      <td>2.134312e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.005228</td>\n",
       "      <td>-0.003544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>-0.001360</td>\n",
       "      <td>0.001154</td>\n",
       "      <td>9.710683e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001016</td>\n",
       "      <td>-0.003735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_group_cleansed</th>\n",
       "      <td>-0.002137</td>\n",
       "      <td>0.002003</td>\n",
       "      <td>9.621981e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001989</td>\n",
       "      <td>-0.006262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              importance    stddev       p_value  n  p99_high  \\\n",
       "description                     0.057559  0.006850  2.361957e-05  5  0.071663   \n",
       "name                            0.055422  0.005438  1.098311e-05  5  0.066620   \n",
       "amenities                       0.055422  0.002236  3.171474e-07  5  0.060026   \n",
       "bathrooms_text                  0.051602  0.005492  1.516627e-05  5  0.062910   \n",
       "property_type                   0.038459  0.003375  7.045760e-06  5  0.045409   \n",
       "neighbourhood_cleansed          0.032373  0.004270  3.550346e-05  5  0.041166   \n",
       "room_type                       0.002007  0.001625  2.538052e-02  5  0.005353   \n",
       "host_verifications              0.000842  0.002130  2.134312e-01  5  0.005228   \n",
       "id                             -0.001360  0.001154  9.710683e-01  5  0.001016   \n",
       "neighbourhood_group_cleansed   -0.002137  0.002003  9.621981e-01  5  0.001989   \n",
       "\n",
       "                               p99_low  \n",
       "description                   0.043455  \n",
       "name                          0.044225  \n",
       "amenities                     0.050819  \n",
       "bathrooms_text                0.040294  \n",
       "property_type                 0.031510  \n",
       "neighbourhood_cleansed        0.023580  \n",
       "room_type                    -0.001339  \n",
       "host_verifications           -0.003544  \n",
       "id                           -0.003735  \n",
       "neighbourhood_group_cleansed -0.006262  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.feature_importance(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
