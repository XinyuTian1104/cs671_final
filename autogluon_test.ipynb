{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.0' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:62: UserWarning: Pandas requires version '1.3.4' or newer of 'bottleneck' (version '1.3.2' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('raw_data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['id'], axis=1)\n",
    "data['location'] = list(zip(data['latitude'], data['longitude']))\n",
    "data = data.drop(['latitude', 'longitude'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = TabularDataset(data)\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20231205_071305\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20231205_071305\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.0.0\n",
      "Python Version:     3.9.7\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   Darwin Kernel Version 23.1.0: Mon Oct  9 21:27:24 PDT 2023; root:xnu-10002.41.9~6/RELEASE_ARM64_T6000\n",
      "CPU Count:          10\n",
      "Memory Avail:       2.54 GB / 32.00 GB (7.9%)\n",
      "Disk Space Avail:   330.82 GB / 926.35 GB (35.7%)\n",
      "===================================================\n",
      "Train Data Rows:    12352\n",
      "Train Data Columns: 45\n",
      "Label Column:       price\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == float, but few unique label-values observed and label-values can be converted to int).\n",
      "\t6 unique label values:  [5.0, 1.0, 2.0, 3.0, 0.0, 4.0]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 6\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2636.77 MB\n",
      "\tTrain Data (Original)  Memory Usage: 39.83 MB (1.5% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 6 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting DatetimeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['name', 'description', 'property_type', 'amenities']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 10000\n",
      "\t\tWarning: Due to memory constraints, ngram feature count is being reduced. Allocate more memory to maximize model quality.\n",
      "\t\tReducing Vectorizer vocab size from 10000 to 2945 to avoid OOM error\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['scrape_id']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 1): ['calendar_last_scraped']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('object', ['datetime_as_object']) : 1 | ['calendar_last_scraped']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])                      :  5 | ['host_listings_count', 'host_total_listings_count', 'beds', 'minimum_nights_avg_ntm', 'maximum_nights_avg_ntm']\n",
      "\t\t('int', [])                        : 19 | ['host_id', 'accommodates', 'minimum_nights', 'maximum_nights', 'minimum_minimum_nights', ...]\n",
      "\t\t('object', [])                     : 13 | ['picture_url', 'host_name', 'host_is_superhost', 'host_verifications', 'host_has_profile_pic', ...]\n",
      "\t\t('object', ['datetime_as_object']) :  2 | ['last_scraped', 'host_since']\n",
      "\t\t('object', ['text'])               :  4 | ['name', 'description', 'property_type', 'amenities']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :    9 | ['picture_url', 'host_name', 'host_is_superhost', 'host_verifications', 'neighbourhood_cleansed', ...]\n",
      "\t\t('category', ['text_as_category'])  :    4 | ['name', 'description', 'property_type', 'amenities']\n",
      "\t\t('float', [])                       :    5 | ['host_listings_count', 'host_total_listings_count', 'beds', 'minimum_nights_avg_ntm', 'maximum_nights_avg_ntm']\n",
      "\t\t('int', [])                         :   19 | ['host_id', 'accommodates', 'minimum_nights', 'maximum_nights', 'minimum_minimum_nights', ...]\n",
      "\t\t('int', ['binned', 'text_special']) :   62 | ['name.char_count', 'name.word_count', 'name.capital_ratio', 'name.lower_ratio', 'name.digit_ratio', ...]\n",
      "\t\t('int', ['bool'])                   :    5 | ['last_scraped', 'host_has_profile_pic', 'host_identity_verified', 'has_availability', 'instant_bookable']\n",
      "\t\t('int', ['datetime_as_int'])        :    5 | ['host_since', 'host_since.year', 'host_since.month', 'host_since.day', 'host_since.dayofweek']\n",
      "\t\t('int', ['text_ngram'])             : 2463 | ['__nlp__.10', '__nlp__.10 min', '__nlp__.10 minutes', '__nlp__.10 years', '__nlp__.10 years old', ...]\n",
      "\t45.6s = Fit runtime\n",
      "\t43 features in original data used to generate 2572 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 61.77 MB (2.4% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 45.88s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 11116, Val Rows: 1236\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\tWarning: Potentially not enough memory to safely train model. Estimated to require 0.412 GB out of 2.620 GB available memory (15.712%)... (20.000% of avail memory is the max safe size)\n",
      "\tTo avoid this warning, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=1.10 to avoid the warning)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\t\tSetting \"ag.max_memory_usage_ratio\" to values above 1 may result in out-of-memory errors. You may consider using a machine with more memory as a safer alternative.\n",
      "\tWarning: Exception caused KNeighborsUnif to fail during training... Skipping this model.\n",
      "\t\t'NoneType' object has no attribute 'split'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1839, in _train_and_save\n",
      "    y_pred_proba_val = model.predict_proba(X_val)\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 949, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, **kwargs)\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 991, in _predict_proba\n",
      "    y_pred_proba = self.model.predict_proba(X)\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py\", line 355, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_base.py\", line 822, in kneighbors\n",
      "    results = ArgKmin.compute(\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 271, in compute\n",
      "    return ArgKmin32.compute(\n",
      "  File \"sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx\", line 575, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin32.compute\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py\", line 74, in threadpool_limits\n",
      "    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/threadpoolctl.py\", line 171, in __init__\n",
      "    self._original_info = self._set_threadpool_limits()\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/threadpoolctl.py\", line 268, in _set_threadpool_limits\n",
      "    modules = _ThreadpoolInfo(prefixes=self._prefixes,\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/threadpoolctl.py\", line 340, in __init__\n",
      "    self._load_modules()\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/threadpoolctl.py\", line 371, in _load_modules\n",
      "    self._find_modules_with_dyld()\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/threadpoolctl.py\", line 428, in _find_modules_with_dyld\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n",
      "Fitting model: KNeighborsDist ...\n",
      "\tWarning: Potentially not enough memory to safely train model. Estimated to require 0.412 GB out of 2.610 GB available memory (15.774%)... (20.000% of avail memory is the max safe size)\n",
      "\tTo avoid this warning, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=1.10 to avoid the warning)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\t\tSetting \"ag.max_memory_usage_ratio\" to values above 1 may result in out-of-memory errors. You may consider using a machine with more memory as a safer alternative.\n",
      "\tWarning: Exception caused KNeighborsDist to fail during training... Skipping this model.\n",
      "\t\t'NoneType' object has no attribute 'split'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1839, in _train_and_save\n",
      "    y_pred_proba_val = model.predict_proba(X_val)\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 949, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, **kwargs)\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 991, in _predict_proba\n",
      "    y_pred_proba = self.model.predict_proba(X)\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py\", line 358, in predict_proba\n",
      "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_base.py\", line 822, in kneighbors\n",
      "    results = ArgKmin.compute(\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 271, in compute\n",
      "    return ArgKmin32.compute(\n",
      "  File \"sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx\", line 575, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin32.compute\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py\", line 74, in threadpool_limits\n",
      "    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/threadpoolctl.py\", line 171, in __init__\n",
      "    self._original_info = self._set_threadpool_limits()\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/threadpoolctl.py\", line 268, in _set_threadpool_limits\n",
      "    modules = _ThreadpoolInfo(prefixes=self._prefixes,\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/threadpoolctl.py\", line 340, in __init__\n",
      "    self._load_modules()\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/threadpoolctl.py\", line 371, in _load_modules\n",
      "    self._find_modules_with_dyld()\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/threadpoolctl.py\", line 428, in _find_modules_with_dyld\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py:200: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py:200: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "No improvement since epoch 6: early stopping\n",
      "/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py:200: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "\t0.5413\t = Validation score   (accuracy)\n",
      "\t12.07s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\tWarning: Exception caused LightGBMXT to fail during training... Skipping this model.\n",
      "\t\tmodule 'pandas.core.strings' has no attribute 'StringMethods'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1817, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1763, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 854, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 98, in _fit\n",
      "    try_import_lightgbm()  # raise helpful error message if LightGBM isn't installed\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/autogluon/common/utils/try_import.py\", line 82, in try_import_lightgbm\n",
      "    import lightgbm\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/lightgbm/__init__.py\", line 8, in <module>\n",
      "    from .basic import Booster, Dataset, Sequence, register_logger\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 21, in <module>\n",
      "    from .compat import PANDAS_INSTALLED, concat, dt_DataTable, pd_CategoricalDtype, pd_DataFrame, pd_Series\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/lightgbm/compat.py\", line 145, in <module>\n",
      "    from dask.dataframe import DataFrame as dask_DataFrame\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/dask/dataframe/__init__.py\", line 3, in <module>\n",
      "    from . import backends, dispatch, rolling\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/dask/dataframe/backends.py\", line 20, in <module>\n",
      "    from .core import DataFrame, Index, Scalar, Series, _Frame\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/dask/dataframe/core.py\", line 52, in <module>\n",
      "    from .accessor import DatetimeAccessor, StringAccessor\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/dask/dataframe/accessor.py\", line 109, in <module>\n",
      "    class StringAccessor(Accessor):\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/dask/dataframe/accessor.py\", line 121, in StringAccessor\n",
      "    @derived_from(pd.core.strings.StringMethods)\n",
      "AttributeError: module 'pandas.core.strings' has no attribute 'StringMethods'\n",
      "Fitting model: LightGBM ...\n",
      "\tWarning: Exception caused LightGBM to fail during training... Skipping this model.\n",
      "\t\tmodule 'pandas.core.strings' has no attribute 'StringMethods'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1817, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1763, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 854, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 98, in _fit\n",
      "    try_import_lightgbm()  # raise helpful error message if LightGBM isn't installed\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/autogluon/common/utils/try_import.py\", line 82, in try_import_lightgbm\n",
      "    import lightgbm\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/lightgbm/__init__.py\", line 8, in <module>\n",
      "    from .basic import Booster, Dataset, Sequence, register_logger\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 21, in <module>\n",
      "    from .compat import PANDAS_INSTALLED, concat, dt_DataTable, pd_CategoricalDtype, pd_DataFrame, pd_Series\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/lightgbm/compat.py\", line 145, in <module>\n",
      "    from dask.dataframe import DataFrame as dask_DataFrame\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/dask/dataframe/__init__.py\", line 3, in <module>\n",
      "    from . import backends, dispatch, rolling\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/dask/dataframe/backends.py\", line 20, in <module>\n",
      "    from .core import DataFrame, Index, Scalar, Series, _Frame\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/dask/dataframe/core.py\", line 52, in <module>\n",
      "    from .accessor import DatetimeAccessor, StringAccessor\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/dask/dataframe/accessor.py\", line 109, in <module>\n",
      "    class StringAccessor(Accessor):\n",
      "  File \"/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/dask/dataframe/accessor.py\", line 121, in StringAccessor\n",
      "    @derived_from(pd.core.strings.StringMethods)\n",
      "AttributeError: module 'pandas.core.strings' has no attribute 'StringMethods'\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.5388\t = Validation score   (accuracy)\n",
      "\t4.58s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.5251\t = Validation score   (accuracy)\n",
      "\t4.51s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\tMany features detected (2572), dynamically setting 'colsample_bylevel' to 0.38880248833592534 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/46/46qfn8750nz4wpqzldyf5qf40000gn/T/ipykernel_25216/13798362.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTabularPredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'price'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/utils/decorators.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mgargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mother_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mgkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/autogluon/tabular/predictor/predictor.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_data, tuning_data, time_limit, presets, hyperparameters, feature_metadata, infer_limit, infer_limit_batch_size, fit_weighted_ensemble, fit_full_last_level_weighted_ensemble, full_weighted_ensemble_additionally, dynamic_stacking, calibrate_decision_threshold, num_cpus, num_gpus, **kwargs)\u001b[0m\n\u001b[1;32m   1107\u001b[0m             \u001b[0mag_fit_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"time_limit\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime_limit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1109\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag_fit_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_fit_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_post_fit_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_post_fit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/autogluon/tabular/predictor/predictor.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, ag_fit_kwargs, ag_post_fit_kwargs)\u001b[0m\n\u001b[1;32m   1113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_fit_kwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_post_fit_kwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msilent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Save predictor to disk to enable prediction and training after interrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1115\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_learner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mag_fit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1116\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_post_fit_vars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_post_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mag_post_fit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/autogluon/tabular/learner/abstract_learner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, X_val, **kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Learner is already fit.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_fit_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     def _fit(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/autogluon/tabular/learner/default_learner.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, X_val, X_unlabeled, holdout_frac, num_bag_folds, num_bag_sets, time_limit, infer_limit, infer_limit_batch_size, verbosity, **trainer_fit_kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         trainer.fit(\n\u001b[0m\u001b[1;32m    129\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/autogluon/tabular/trainer/auto_trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, hyperparameters, X_val, y_val, X_unlabeled, holdout_frac, num_stack_levels, core_kwargs, aux_kwargs, time_limit, infer_limit, infer_limit_batch_size, use_bag_holdout, groups, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         self._train_multi_and_ensemble(\n\u001b[0m\u001b[1;32m    126\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\u001b[0m in \u001b[0;36m_train_multi_and_ensemble\u001b[0;34m(self, X, y, X_val, y_val, hyperparameters, X_unlabeled, num_stack_levels, time_limit, groups, **kwargs)\u001b[0m\n\u001b[1;32m   2501\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_rows_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2502\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_cols_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2503\u001b[0;31m         model_names_fit = self.train_multi_levels(\n\u001b[0m\u001b[1;32m   2504\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2505\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\u001b[0m in \u001b[0;36mtrain_multi_levels\u001b[0;34m(self, X, y, hyperparameters, X_val, y_val, X_unlabeled, base_model_names, core_kwargs, aux_kwargs, level_start, level_end, time_limit, name_suffix, relative_stack, level_time_modifier, infer_limit, infer_limit_batch_size)\u001b[0m\n\u001b[1;32m    386\u001b[0m                 \u001b[0mcore_kwargs_level\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"time_limit\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcore_kwargs_level\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"time_limit\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_limit_core\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m                 \u001b[0maux_kwargs_level\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"time_limit\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maux_kwargs_level\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"time_limit\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_limit_aux\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m             base_model_names, aux_models = self.stack_new_level(\n\u001b[0m\u001b[1;32m    389\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m                 \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\u001b[0m in \u001b[0;36mstack_new_level\u001b[0;34m(self, X, y, models, X_val, y_val, X_unlabeled, level, base_model_names, core_kwargs, aux_kwargs, name_suffix, infer_limit, infer_limit_batch_size, full_weighted_ensemble, additional_full_weighted_ensemble)\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mcore_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"name_suffix\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcore_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"name_suffix\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname_suffix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m             \u001b[0maux_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"name_suffix\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maux_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"name_suffix\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname_suffix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 536\u001b[0;31m         core_models = self.stack_new_level_core(\n\u001b[0m\u001b[1;32m    537\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\u001b[0m in \u001b[0;36mstack_new_level_core\u001b[0;34m(self, X, y, models, X_val, y_val, X_unlabeled, level, base_model_names, stack_name, ag_args, ag_args_fit, ag_args_ensemble, included_model_types, excluded_model_types, ensemble_type, name_suffix, get_models_func, refit_full, infer_limit, infer_limit_batch_size, **kwargs)\u001b[0m\n\u001b[1;32m    664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m         \u001b[0;31m# FIXME: TODO: v0.1 X_unlabeled isn't cached so it won't be available during refit_full or fit_extra.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 666\u001b[0;31m         return self._train_multi(\n\u001b[0m\u001b[1;32m    667\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_init\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\u001b[0m in \u001b[0;36m_train_multi\u001b[0;34m(self, X, y, models, hyperparameter_tune_kwargs, feature_prune_kwargs, k_fold, n_repeats, n_repeat_start, time_limit, **kwargs)\u001b[0m\n\u001b[1;32m   2451\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_repeat_start\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2452\u001b[0m             \u001b[0mtime_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2453\u001b[0;31m             model_names_trained = self._train_multi_initial(\n\u001b[0m\u001b[1;32m   2454\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2455\u001b[0m                 \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\u001b[0m in \u001b[0;36m_train_multi_initial\u001b[0;34m(self, X, y, models, k_fold, n_repeats, hyperparameter_tune_kwargs, time_limit, feature_prune_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m   2290\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbagged\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2291\u001b[0m             \u001b[0mtime_ratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhpo_time_ratio\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhpo_enabled\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2292\u001b[0;31m             models = self._train_multi_fold(\n\u001b[0m\u001b[1;32m   2293\u001b[0m                 \u001b[0mmodels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2294\u001b[0m                 \u001b[0mhyperparameter_tune_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhyperparameter_tune_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\u001b[0m in \u001b[0;36m_train_multi_fold\u001b[0;34m(self, X, y, models, time_limit, time_split, time_ratio, hyperparameter_tune_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m   2408\u001b[0m                     \u001b[0mtime_start_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2409\u001b[0m                     \u001b[0mtime_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime_limit\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime_start_model\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2410\u001b[0;31m             model_name_trained_lst = self._train_single_full(\n\u001b[0m\u001b[1;32m   2411\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_left\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparameter_tune_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhyperparameter_tune_kwargs_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2412\u001b[0m             )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\u001b[0m in \u001b[0;36m_train_single_full\u001b[0;34m(self, X, y, model, X_unlabeled, X_val, y_val, X_pseudo, y_pseudo, feature_prune, hyperparameter_tune_kwargs, stack_name, k_fold, k_fold_start, k_fold_end, n_repeats, n_repeat_start, level, time_limit, fit_kwargs, compute_score, total_resources, **kwargs)\u001b[0m\n\u001b[1;32m   2181\u001b[0m                 )\n\u001b[1;32m   2182\u001b[0m                 \u001b[0mmodel_fit_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbagged_model_fit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2183\u001b[0;31m             model_names_trained = self._train_and_save(\n\u001b[0m\u001b[1;32m   2184\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2185\u001b[0m                 \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\u001b[0m in \u001b[0;36m_train_and_save\u001b[0;34m(self, X, y, model, X_val, y_val, stack_name, level, compute_score, total_resources, **model_fit_kwargs)\u001b[0m\n\u001b[1;32m   1815\u001b[0m                 \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_w_pseudo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_w_pseudo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_fit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1816\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1817\u001b[0;31m                 \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_resources\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_resources\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_fit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1819\u001b[0m             \u001b[0mfit_end_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\u001b[0m in \u001b[0;36m_train_single\u001b[0;34m(self, X, y, model, X_val, y_val, total_resources, **model_fit_kwargs)\u001b[0m\n\u001b[1;32m   1761\u001b[0m         \u001b[0mReturns\u001b[0m \u001b[0mtrained\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1762\u001b[0m         \"\"\"\n\u001b[0;32m-> 1763\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_resources\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_resources\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_fit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1764\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    852\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_fit_resources\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_fit_memory_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 854\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    855\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/autogluon/tabular/models/catboost/catboost_model.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, X_val, y_val, time_limit, num_gpus, num_cpus, sample_weight, sample_weight_val, **kwargs)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0mfit_final_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"use_best_model\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_final_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams_trained\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"iterations\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_count_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   5126\u001b[0m             \u001b[0mCatBoostClassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_is_compatible_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss_function'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5128\u001b[0;31m         self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n\u001b[0m\u001b[1;32m   5129\u001b[0m                   \u001b[0meval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_description\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_period\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5130\u001b[0m                   silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   2353\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mlog_fixup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_cout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_cerr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2354\u001b[0m             \u001b[0mplot_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Training plots'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_get_train_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2355\u001b[0;31m             self._train(\n\u001b[0m\u001b[1;32m   2356\u001b[0m                 \u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2357\u001b[0m                 \u001b[0mtrain_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"eval_sets\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m_train\u001b[0;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1758\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1759\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minit_model\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1760\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_trained_model_attributes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor(label='price').fit(train_data=train_data)\n",
    "predictions = predictor.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py:200: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.587569</td>\n",
       "      <td>0.597896</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>1.465020</td>\n",
       "      <td>0.606684</td>\n",
       "      <td>270.735472</td>\n",
       "      <td>0.002915</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>0.291649</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.568792</td>\n",
       "      <td>0.576052</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.244883</td>\n",
       "      <td>0.123203</td>\n",
       "      <td>176.374890</td>\n",
       "      <td>0.244883</td>\n",
       "      <td>0.123203</td>\n",
       "      <td>176.374890</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.563289</td>\n",
       "      <td>0.566343</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.415553</td>\n",
       "      <td>0.125623</td>\n",
       "      <td>43.932831</td>\n",
       "      <td>0.415553</td>\n",
       "      <td>0.125623</td>\n",
       "      <td>43.932831</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestGini</td>\n",
       "      <td>0.547426</td>\n",
       "      <td>0.545307</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.192787</td>\n",
       "      <td>0.070838</td>\n",
       "      <td>5.677691</td>\n",
       "      <td>0.192787</td>\n",
       "      <td>0.070838</td>\n",
       "      <td>5.677691</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestEntr</td>\n",
       "      <td>0.539657</td>\n",
       "      <td>0.533981</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.164829</td>\n",
       "      <td>0.070584</td>\n",
       "      <td>5.447723</td>\n",
       "      <td>0.164829</td>\n",
       "      <td>0.070584</td>\n",
       "      <td>5.447723</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ExtraTreesEntr</td>\n",
       "      <td>0.535125</td>\n",
       "      <td>0.531553</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.160795</td>\n",
       "      <td>0.072332</td>\n",
       "      <td>5.608540</td>\n",
       "      <td>0.160795</td>\n",
       "      <td>0.072332</td>\n",
       "      <td>5.608540</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ExtraTreesGini</td>\n",
       "      <td>0.534801</td>\n",
       "      <td>0.541262</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.163504</td>\n",
       "      <td>0.073445</td>\n",
       "      <td>5.706276</td>\n",
       "      <td>0.163504</td>\n",
       "      <td>0.073445</td>\n",
       "      <td>5.706276</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NeuralNetTorch</td>\n",
       "      <td>0.526060</td>\n",
       "      <td>0.540453</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.068331</td>\n",
       "      <td>0.048484</td>\n",
       "      <td>16.113814</td>\n",
       "      <td>0.068331</td>\n",
       "      <td>0.048484</td>\n",
       "      <td>16.113814</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NeuralNetFastAI</td>\n",
       "      <td>0.515053</td>\n",
       "      <td>0.541262</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.051423</td>\n",
       "      <td>0.021721</td>\n",
       "      <td>11.582058</td>\n",
       "      <td>0.051423</td>\n",
       "      <td>0.021721</td>\n",
       "      <td>11.582058</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  score_test  score_val eval_metric  pred_time_test  \\\n",
       "0  WeightedEnsemble_L2    0.587569   0.597896    accuracy        1.465020   \n",
       "1             CatBoost    0.568792   0.576052    accuracy        0.244883   \n",
       "2              XGBoost    0.563289   0.566343    accuracy        0.415553   \n",
       "3     RandomForestGini    0.547426   0.545307    accuracy        0.192787   \n",
       "4     RandomForestEntr    0.539657   0.533981    accuracy        0.164829   \n",
       "5       ExtraTreesEntr    0.535125   0.531553    accuracy        0.160795   \n",
       "6       ExtraTreesGini    0.534801   0.541262    accuracy        0.163504   \n",
       "7       NeuralNetTorch    0.526060   0.540453    accuracy        0.068331   \n",
       "8      NeuralNetFastAI    0.515053   0.541262    accuracy        0.051423   \n",
       "\n",
       "   pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
       "0       0.606684  270.735472                 0.002915                0.000454   \n",
       "1       0.123203  176.374890                 0.244883                0.123203   \n",
       "2       0.125623   43.932831                 0.415553                0.125623   \n",
       "3       0.070838    5.677691                 0.192787                0.070838   \n",
       "4       0.070584    5.447723                 0.164829                0.070584   \n",
       "5       0.072332    5.608540                 0.160795                0.072332   \n",
       "6       0.073445    5.706276                 0.163504                0.073445   \n",
       "7       0.048484   16.113814                 0.068331                0.048484   \n",
       "8       0.021721   11.582058                 0.051423                0.021721   \n",
       "\n",
       "   fit_time_marginal  stack_level  can_infer  fit_order  \n",
       "0           0.291649            2       True          9  \n",
       "1         176.374890            1       True          4  \n",
       "2          43.932831            1       True          7  \n",
       "3           5.677691            1       True          2  \n",
       "4           5.447723            1       True          3  \n",
       "5           5.608540            1       True          6  \n",
       "6           5.706276            1       True          5  \n",
       "7          16.113814            1       True          8  \n",
       "8          11.582058            1       True          1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(test_data, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                 model  score_val eval_metric  pred_time_val    fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0  WeightedEnsemble_L2   0.597896    accuracy       0.606684  270.735472                0.000454           0.291649            2       True          9\n",
      "1             CatBoost   0.576052    accuracy       0.123203  176.374890                0.123203         176.374890            1       True          4\n",
      "2              XGBoost   0.566343    accuracy       0.125623   43.932831                0.125623          43.932831            1       True          7\n",
      "3     RandomForestGini   0.545307    accuracy       0.070838    5.677691                0.070838           5.677691            1       True          2\n",
      "4      NeuralNetFastAI   0.541262    accuracy       0.021721   11.582058                0.021721          11.582058            1       True          1\n",
      "5       ExtraTreesGini   0.541262    accuracy       0.073445    5.706276                0.073445           5.706276            1       True          5\n",
      "6       NeuralNetTorch   0.540453    accuracy       0.048484   16.113814                0.048484          16.113814            1       True          8\n",
      "7     RandomForestEntr   0.533981    accuracy       0.070584    5.447723                0.070584           5.447723            1       True          3\n",
      "8       ExtraTreesEntr   0.531553    accuracy       0.072332    5.608540                0.072332           5.608540            1       True          6\n",
      "Number of models trained: 9\n",
      "Types of models trained:\n",
      "{'XGBoostModel', 'TabularNeuralNetTorchModel', 'WeightedEnsembleModel', 'NNFastAiTabularModel', 'RFModel', 'CatBoostModel', 'XTModel'}\n",
      "Bagging used: False \n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('category', [])                    :    9 | ['picture_url', 'host_name', 'host_is_superhost', 'host_verifications', 'neighbourhood_cleansed', ...]\n",
      "('category', ['text_as_category'])  :    4 | ['name', 'description', 'property_type', 'amenities']\n",
      "('float', [])                       :    5 | ['host_listings_count', 'host_total_listings_count', 'beds', 'minimum_nights_avg_ntm', 'maximum_nights_avg_ntm']\n",
      "('int', [])                         :   19 | ['host_id', 'accommodates', 'minimum_nights', 'maximum_nights', 'minimum_minimum_nights', ...]\n",
      "('int', ['binned', 'text_special']) :   62 | ['name.char_count', 'name.word_count', 'name.capital_ratio', 'name.lower_ratio', 'name.digit_ratio', ...]\n",
      "('int', ['bool'])                   :    5 | ['last_scraped', 'host_has_profile_pic', 'host_identity_verified', 'has_availability', 'instant_bookable']\n",
      "('int', ['datetime_as_int'])        :    5 | ['host_since', 'host_since.year', 'host_since.month', 'host_since.day', 'host_since.dayofweek']\n",
      "('int', ['text_ngram'])             : 4350 | ['__nlp__.000', '__nlp__.10', '__nlp__.10 min', '__nlp__.10 minute', '__nlp__.10 minutes', ...]\n",
      "Plot summary of models saved to file: AutogluonModels/ag-20231205_014907SummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_types': {'NeuralNetFastAI': 'NNFastAiTabularModel',\n",
       "  'RandomForestGini': 'RFModel',\n",
       "  'RandomForestEntr': 'RFModel',\n",
       "  'CatBoost': 'CatBoostModel',\n",
       "  'ExtraTreesGini': 'XTModel',\n",
       "  'ExtraTreesEntr': 'XTModel',\n",
       "  'XGBoost': 'XGBoostModel',\n",
       "  'NeuralNetTorch': 'TabularNeuralNetTorchModel',\n",
       "  'WeightedEnsemble_L2': 'WeightedEnsembleModel'},\n",
       " 'model_performance': {'NeuralNetFastAI': 0.5412621359223301,\n",
       "  'RandomForestGini': 0.5453074433656958,\n",
       "  'RandomForestEntr': 0.5339805825242718,\n",
       "  'CatBoost': 0.5760517799352751,\n",
       "  'ExtraTreesGini': 0.5412621359223301,\n",
       "  'ExtraTreesEntr': 0.5315533980582524,\n",
       "  'XGBoost': 0.5663430420711975,\n",
       "  'NeuralNetTorch': 0.540453074433657,\n",
       "  'WeightedEnsemble_L2': 0.5978964401294499},\n",
       " 'model_best': 'WeightedEnsemble_L2',\n",
       " 'model_paths': {'NeuralNetFastAI': ['NeuralNetFastAI'],\n",
       "  'RandomForestGini': ['RandomForestGini'],\n",
       "  'RandomForestEntr': ['RandomForestEntr'],\n",
       "  'CatBoost': ['CatBoost'],\n",
       "  'ExtraTreesGini': ['ExtraTreesGini'],\n",
       "  'ExtraTreesEntr': ['ExtraTreesEntr'],\n",
       "  'XGBoost': ['XGBoost'],\n",
       "  'NeuralNetTorch': ['NeuralNetTorch'],\n",
       "  'WeightedEnsemble_L2': ['WeightedEnsemble_L2']},\n",
       " 'model_fit_times': {'NeuralNetFastAI': 11.58205795288086,\n",
       "  'RandomForestGini': 5.677691221237183,\n",
       "  'RandomForestEntr': 5.447722911834717,\n",
       "  'CatBoost': 176.37488985061646,\n",
       "  'ExtraTreesGini': 5.706275939941406,\n",
       "  'ExtraTreesEntr': 5.608540058135986,\n",
       "  'XGBoost': 43.932831048965454,\n",
       "  'NeuralNetTorch': 16.113813877105713,\n",
       "  'WeightedEnsemble_L2': 0.29164886474609375},\n",
       " 'model_pred_times': {'NeuralNetFastAI': 0.02172112464904785,\n",
       "  'RandomForestGini': 0.07083797454833984,\n",
       "  'RandomForestEntr': 0.07058405876159668,\n",
       "  'CatBoost': 0.12320280075073242,\n",
       "  'ExtraTreesGini': 0.07344484329223633,\n",
       "  'ExtraTreesEntr': 0.07233214378356934,\n",
       "  'XGBoost': 0.12562298774719238,\n",
       "  'NeuralNetTorch': 0.04848432540893555,\n",
       "  'WeightedEnsemble_L2': 0.000453948974609375},\n",
       " 'num_bag_folds': 0,\n",
       " 'max_stack_level': 2,\n",
       " 'num_classes': 6,\n",
       " 'model_hyperparams': {'NeuralNetFastAI': {'layers': None,\n",
       "   'emb_drop': 0.1,\n",
       "   'ps': 0.1,\n",
       "   'bs': 'auto',\n",
       "   'lr': 0.01,\n",
       "   'epochs': 'auto',\n",
       "   'early.stopping.min_delta': 0.0001,\n",
       "   'early.stopping.patience': 20,\n",
       "   'smoothing': 0.0},\n",
       "  'RandomForestGini': {'n_estimators': 300,\n",
       "   'max_leaf_nodes': 15000,\n",
       "   'n_jobs': -1,\n",
       "   'random_state': 0,\n",
       "   'bootstrap': True,\n",
       "   'criterion': 'gini'},\n",
       "  'RandomForestEntr': {'n_estimators': 300,\n",
       "   'max_leaf_nodes': 15000,\n",
       "   'n_jobs': -1,\n",
       "   'random_state': 0,\n",
       "   'bootstrap': True,\n",
       "   'criterion': 'entropy'},\n",
       "  'CatBoost': {'iterations': 10000,\n",
       "   'learning_rate': 0.05,\n",
       "   'random_seed': 0,\n",
       "   'allow_writing_files': False,\n",
       "   'eval_metric': 'Accuracy'},\n",
       "  'ExtraTreesGini': {'n_estimators': 300,\n",
       "   'max_leaf_nodes': 15000,\n",
       "   'n_jobs': -1,\n",
       "   'random_state': 0,\n",
       "   'bootstrap': True,\n",
       "   'criterion': 'gini'},\n",
       "  'ExtraTreesEntr': {'n_estimators': 300,\n",
       "   'max_leaf_nodes': 15000,\n",
       "   'n_jobs': -1,\n",
       "   'random_state': 0,\n",
       "   'bootstrap': True,\n",
       "   'criterion': 'entropy'},\n",
       "  'XGBoost': {'n_estimators': 10000,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_jobs': -1,\n",
       "   'proc.max_category_levels': 100,\n",
       "   'objective': 'multi:softprob',\n",
       "   'booster': 'gbtree',\n",
       "   'num_class': 6},\n",
       "  'NeuralNetTorch': {'num_epochs': 500,\n",
       "   'epochs_wo_improve': 20,\n",
       "   'activation': 'relu',\n",
       "   'embedding_size_factor': 1.0,\n",
       "   'embed_exponent': 0.56,\n",
       "   'max_embedding_dim': 100,\n",
       "   'y_range': None,\n",
       "   'y_range_extend': 0.05,\n",
       "   'dropout_prob': 0.1,\n",
       "   'optimizer': 'adam',\n",
       "   'learning_rate': 0.0003,\n",
       "   'weight_decay': 1e-06,\n",
       "   'proc.embed_min_categories': 4,\n",
       "   'proc.impute_strategy': 'median',\n",
       "   'proc.max_category_levels': 100,\n",
       "   'proc.skew_threshold': 0.99,\n",
       "   'use_ngram_features': False,\n",
       "   'num_layers': 4,\n",
       "   'hidden_size': 128,\n",
       "   'max_batch_size': 512,\n",
       "   'use_batchnorm': False,\n",
       "   'loss_function': 'auto'},\n",
       "  'WeightedEnsemble_L2': {'use_orig_features': False,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True}},\n",
       " 'leaderboard':                  model  score_val eval_metric  pred_time_val    fit_time  \\\n",
       " 0  WeightedEnsemble_L2   0.597896    accuracy       0.606684  270.735472   \n",
       " 1             CatBoost   0.576052    accuracy       0.123203  176.374890   \n",
       " 2              XGBoost   0.566343    accuracy       0.125623   43.932831   \n",
       " 3     RandomForestGini   0.545307    accuracy       0.070838    5.677691   \n",
       " 4      NeuralNetFastAI   0.541262    accuracy       0.021721   11.582058   \n",
       " 5       ExtraTreesGini   0.541262    accuracy       0.073445    5.706276   \n",
       " 6       NeuralNetTorch   0.540453    accuracy       0.048484   16.113814   \n",
       " 7     RandomForestEntr   0.533981    accuracy       0.070584    5.447723   \n",
       " 8       ExtraTreesEntr   0.531553    accuracy       0.072332    5.608540   \n",
       " \n",
       "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       " 0                0.000454           0.291649            2       True   \n",
       " 1                0.123203         176.374890            1       True   \n",
       " 2                0.125623          43.932831            1       True   \n",
       " 3                0.070838           5.677691            1       True   \n",
       " 4                0.021721          11.582058            1       True   \n",
       " 5                0.073445           5.706276            1       True   \n",
       " 6                0.048484          16.113814            1       True   \n",
       " 7                0.070584           5.447723            1       True   \n",
       " 8                0.072332           5.608540            1       True   \n",
       " \n",
       "    fit_order  \n",
       " 0          9  \n",
       " 1          4  \n",
       " 2          7  \n",
       " 3          2  \n",
       " 4          1  \n",
       " 5          5  \n",
       " 6          8  \n",
       " 7          3  \n",
       " 8          6  }"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.fit_summary(show_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "These features in provided data are not utilized by the predictor and will be ignored: ['scrape_id', 'calendar_last_scraped']\n",
      "Computing feature importance via permutation shuffling for 43 features using 3089 rows with 5 shuffle sets...\n",
      "/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py:200: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "\t838.14s\t= Expected runtime (167.63s per shuffle set)\n",
      "/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py:200: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py:200: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py:200: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py:200: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py:200: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py:200: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py:200: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py:200: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py:200: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py:200: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py:200: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py:200: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py:200: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py:200: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "/Users/xinyutian/opt/anaconda3/lib/python3.9/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py:200: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "\t709.37s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>stddev</th>\n",
       "      <th>p_value</th>\n",
       "      <th>n</th>\n",
       "      <th>p99_high</th>\n",
       "      <th>p99_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>amenities</th>\n",
       "      <td>0.041114</td>\n",
       "      <td>0.003726</td>\n",
       "      <td>8.010434e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.048786</td>\n",
       "      <td>0.033441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bathrooms_text</th>\n",
       "      <td>0.040337</td>\n",
       "      <td>0.003536</td>\n",
       "      <td>7.013800e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.047617</td>\n",
       "      <td>0.033056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed</th>\n",
       "      <td>0.040013</td>\n",
       "      <td>0.001459</td>\n",
       "      <td>2.115097e-07</td>\n",
       "      <td>5</td>\n",
       "      <td>0.043016</td>\n",
       "      <td>0.037010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>property_type</th>\n",
       "      <td>0.035287</td>\n",
       "      <td>0.005460</td>\n",
       "      <td>6.666524e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.046530</td>\n",
       "      <td>0.024043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>description</th>\n",
       "      <td>0.028812</td>\n",
       "      <td>0.003080</td>\n",
       "      <td>1.542877e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.035153</td>\n",
       "      <td>0.022471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <td>0.025316</td>\n",
       "      <td>0.003049</td>\n",
       "      <td>2.476559e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.031593</td>\n",
       "      <td>0.019038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_name</th>\n",
       "      <td>0.015539</td>\n",
       "      <td>0.005460</td>\n",
       "      <td>1.563359e-03</td>\n",
       "      <td>5</td>\n",
       "      <td>0.026782</td>\n",
       "      <td>0.004296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accommodates</th>\n",
       "      <td>0.014115</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>1.280397e-03</td>\n",
       "      <td>5</td>\n",
       "      <td>0.023792</td>\n",
       "      <td>0.004437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_since</th>\n",
       "      <td>0.003043</td>\n",
       "      <td>0.002029</td>\n",
       "      <td>1.424640e-02</td>\n",
       "      <td>5</td>\n",
       "      <td>0.007222</td>\n",
       "      <td>-0.001136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>availability_30</th>\n",
       "      <td>0.002784</td>\n",
       "      <td>0.001135</td>\n",
       "      <td>2.693700e-03</td>\n",
       "      <td>5</td>\n",
       "      <td>0.005122</td>\n",
       "      <td>0.000446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_reviews_l30d</th>\n",
       "      <td>0.002719</td>\n",
       "      <td>0.001476</td>\n",
       "      <td>7.315526e-03</td>\n",
       "      <td>5</td>\n",
       "      <td>0.005759</td>\n",
       "      <td>-0.000321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_reviews_ltm</th>\n",
       "      <td>0.002460</td>\n",
       "      <td>0.002363</td>\n",
       "      <td>4.022540e-02</td>\n",
       "      <td>5</td>\n",
       "      <td>0.007327</td>\n",
       "      <td>-0.002406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minimum_minimum_nights</th>\n",
       "      <td>0.002266</td>\n",
       "      <td>0.001189</td>\n",
       "      <td>6.526468e-03</td>\n",
       "      <td>5</td>\n",
       "      <td>0.004715</td>\n",
       "      <td>-0.000183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>availability_60</th>\n",
       "      <td>0.002007</td>\n",
       "      <td>0.001283</td>\n",
       "      <td>1.246091e-02</td>\n",
       "      <td>5</td>\n",
       "      <td>0.004648</td>\n",
       "      <td>-0.000634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minimum_nights</th>\n",
       "      <td>0.001748</td>\n",
       "      <td>0.001767</td>\n",
       "      <td>4.571492e-02</td>\n",
       "      <td>5</td>\n",
       "      <td>0.005387</td>\n",
       "      <td>-0.001891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_group_cleansed</th>\n",
       "      <td>0.001683</td>\n",
       "      <td>0.001988</td>\n",
       "      <td>6.559237e-02</td>\n",
       "      <td>5</td>\n",
       "      <td>0.005776</td>\n",
       "      <td>-0.002409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>room_type</th>\n",
       "      <td>0.001619</td>\n",
       "      <td>0.000724</td>\n",
       "      <td>3.745217e-03</td>\n",
       "      <td>5</td>\n",
       "      <td>0.003109</td>\n",
       "      <td>0.000128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maximum_minimum_nights</th>\n",
       "      <td>0.001619</td>\n",
       "      <td>0.002323</td>\n",
       "      <td>9.712274e-02</td>\n",
       "      <td>5</td>\n",
       "      <td>0.006402</td>\n",
       "      <td>-0.003165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>availability_90</th>\n",
       "      <td>0.001295</td>\n",
       "      <td>0.001315</td>\n",
       "      <td>4.622690e-02</td>\n",
       "      <td>5</td>\n",
       "      <td>0.004003</td>\n",
       "      <td>-0.001413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_id</th>\n",
       "      <td>0.001295</td>\n",
       "      <td>0.001666</td>\n",
       "      <td>7.864953e-02</td>\n",
       "      <td>5</td>\n",
       "      <td>0.004726</td>\n",
       "      <td>-0.002136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_verifications</th>\n",
       "      <td>0.001165</td>\n",
       "      <td>0.001112</td>\n",
       "      <td>3.954185e-02</td>\n",
       "      <td>5</td>\n",
       "      <td>0.003455</td>\n",
       "      <td>-0.001124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minimum_nights_avg_ntm</th>\n",
       "      <td>0.001101</td>\n",
       "      <td>0.002892</td>\n",
       "      <td>2.213413e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.007055</td>\n",
       "      <td>-0.004854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calculated_host_listings_count_entire_homes</th>\n",
       "      <td>0.000971</td>\n",
       "      <td>0.001518</td>\n",
       "      <td>1.129455e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.004098</td>\n",
       "      <td>-0.002155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_identity_verified</th>\n",
       "      <td>0.000971</td>\n",
       "      <td>0.001392</td>\n",
       "      <td>9.693005e-02</td>\n",
       "      <td>5</td>\n",
       "      <td>0.003838</td>\n",
       "      <td>-0.001896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_listings_count</th>\n",
       "      <td>0.000906</td>\n",
       "      <td>0.001283</td>\n",
       "      <td>9.461413e-02</td>\n",
       "      <td>5</td>\n",
       "      <td>0.003548</td>\n",
       "      <td>-0.001735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>availability_365</th>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.002080</td>\n",
       "      <td>2.253271e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.005061</td>\n",
       "      <td>-0.003507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_availability</th>\n",
       "      <td>0.000453</td>\n",
       "      <td>0.000671</td>\n",
       "      <td>1.028200e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001835</td>\n",
       "      <td>-0.000929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_has_profile_pic</th>\n",
       "      <td>0.000259</td>\n",
       "      <td>0.000422</td>\n",
       "      <td>1.209908e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001128</td>\n",
       "      <td>-0.000610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calculated_host_listings_count_private_rooms</th>\n",
       "      <td>0.000259</td>\n",
       "      <td>0.001808</td>\n",
       "      <td>3.824028e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.003982</td>\n",
       "      <td>-0.003464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_scraped</th>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000542</td>\n",
       "      <td>2.338024e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001310</td>\n",
       "      <td>-0.000921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_is_superhost</th>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000671</td>\n",
       "      <td>2.764447e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001576</td>\n",
       "      <td>-0.001188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beds</th>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.001660</td>\n",
       "      <td>4.350081e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.003548</td>\n",
       "      <td>-0.003289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>picture_url</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calculated_host_listings_count_shared_rooms</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>-0.000471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maximum_maximum_nights</th>\n",
       "      <td>-0.000065</td>\n",
       "      <td>0.000422</td>\n",
       "      <td>6.255658e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000804</td>\n",
       "      <td>-0.000934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location</th>\n",
       "      <td>-0.000065</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>5.925490e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001128</td>\n",
       "      <td>-0.001257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_reviews</th>\n",
       "      <td>-0.000194</td>\n",
       "      <td>0.001923</td>\n",
       "      <td>5.837922e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.003766</td>\n",
       "      <td>-0.004155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_total_listings_count</th>\n",
       "      <td>-0.000194</td>\n",
       "      <td>0.001579</td>\n",
       "      <td>6.015353e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.003058</td>\n",
       "      <td>-0.003446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maximum_nights_avg_ntm</th>\n",
       "      <td>-0.000259</td>\n",
       "      <td>0.001542</td>\n",
       "      <td>6.368094e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.002917</td>\n",
       "      <td>-0.003435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <td>-0.000388</td>\n",
       "      <td>0.000623</td>\n",
       "      <td>8.822518e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000894</td>\n",
       "      <td>-0.001671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minimum_maximum_nights</th>\n",
       "      <td>-0.000518</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>9.611292e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>-0.001529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instant_bookable</th>\n",
       "      <td>-0.000518</td>\n",
       "      <td>0.001064</td>\n",
       "      <td>8.312491e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001673</td>\n",
       "      <td>-0.002709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maximum_nights</th>\n",
       "      <td>-0.000842</td>\n",
       "      <td>0.000745</td>\n",
       "      <td>9.675070e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000693</td>\n",
       "      <td>-0.002376</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              importance    stddev  \\\n",
       "amenities                                       0.041114  0.003726   \n",
       "bathrooms_text                                  0.040337  0.003536   \n",
       "neighbourhood_cleansed                          0.040013  0.001459   \n",
       "property_type                                   0.035287  0.005460   \n",
       "description                                     0.028812  0.003080   \n",
       "name                                            0.025316  0.003049   \n",
       "host_name                                       0.015539  0.005460   \n",
       "accommodates                                    0.014115  0.004700   \n",
       "host_since                                      0.003043  0.002029   \n",
       "availability_30                                 0.002784  0.001135   \n",
       "number_of_reviews_l30d                          0.002719  0.001476   \n",
       "number_of_reviews_ltm                           0.002460  0.002363   \n",
       "minimum_minimum_nights                          0.002266  0.001189   \n",
       "availability_60                                 0.002007  0.001283   \n",
       "minimum_nights                                  0.001748  0.001767   \n",
       "neighbourhood_group_cleansed                    0.001683  0.001988   \n",
       "room_type                                       0.001619  0.000724   \n",
       "maximum_minimum_nights                          0.001619  0.002323   \n",
       "availability_90                                 0.001295  0.001315   \n",
       "host_id                                         0.001295  0.001666   \n",
       "host_verifications                              0.001165  0.001112   \n",
       "minimum_nights_avg_ntm                          0.001101  0.002892   \n",
       "calculated_host_listings_count_entire_homes     0.000971  0.001518   \n",
       "host_identity_verified                          0.000971  0.001392   \n",
       "host_listings_count                             0.000906  0.001283   \n",
       "availability_365                                0.000777  0.002080   \n",
       "has_availability                                0.000453  0.000671   \n",
       "host_has_profile_pic                            0.000259  0.000422   \n",
       "calculated_host_listings_count_private_rooms    0.000259  0.001808   \n",
       "last_scraped                                    0.000194  0.000542   \n",
       "host_is_superhost                               0.000194  0.000671   \n",
       "beds                                            0.000129  0.001660   \n",
       "picture_url                                     0.000000  0.000000   \n",
       "calculated_host_listings_count_shared_rooms     0.000000  0.000229   \n",
       "maximum_maximum_nights                         -0.000065  0.000422   \n",
       "location                                       -0.000065  0.000579   \n",
       "number_of_reviews                              -0.000194  0.001923   \n",
       "host_total_listings_count                      -0.000194  0.001579   \n",
       "maximum_nights_avg_ntm                         -0.000259  0.001542   \n",
       "calculated_host_listings_count                 -0.000388  0.000623   \n",
       "minimum_maximum_nights                         -0.000518  0.000491   \n",
       "instant_bookable                               -0.000518  0.001064   \n",
       "maximum_nights                                 -0.000842  0.000745   \n",
       "\n",
       "                                                   p_value  n  p99_high  \\\n",
       "amenities                                     8.010434e-06  5  0.048786   \n",
       "bathrooms_text                                7.013800e-06  5  0.047617   \n",
       "neighbourhood_cleansed                        2.115097e-07  5  0.043016   \n",
       "property_type                                 6.666524e-05  5  0.046530   \n",
       "description                                   1.542877e-05  5  0.035153   \n",
       "name                                          2.476559e-05  5  0.031593   \n",
       "host_name                                     1.563359e-03  5  0.026782   \n",
       "accommodates                                  1.280397e-03  5  0.023792   \n",
       "host_since                                    1.424640e-02  5  0.007222   \n",
       "availability_30                               2.693700e-03  5  0.005122   \n",
       "number_of_reviews_l30d                        7.315526e-03  5  0.005759   \n",
       "number_of_reviews_ltm                         4.022540e-02  5  0.007327   \n",
       "minimum_minimum_nights                        6.526468e-03  5  0.004715   \n",
       "availability_60                               1.246091e-02  5  0.004648   \n",
       "minimum_nights                                4.571492e-02  5  0.005387   \n",
       "neighbourhood_group_cleansed                  6.559237e-02  5  0.005776   \n",
       "room_type                                     3.745217e-03  5  0.003109   \n",
       "maximum_minimum_nights                        9.712274e-02  5  0.006402   \n",
       "availability_90                               4.622690e-02  5  0.004003   \n",
       "host_id                                       7.864953e-02  5  0.004726   \n",
       "host_verifications                            3.954185e-02  5  0.003455   \n",
       "minimum_nights_avg_ntm                        2.213413e-01  5  0.007055   \n",
       "calculated_host_listings_count_entire_homes   1.129455e-01  5  0.004098   \n",
       "host_identity_verified                        9.693005e-02  5  0.003838   \n",
       "host_listings_count                           9.461413e-02  5  0.003548   \n",
       "availability_365                              2.253271e-01  5  0.005061   \n",
       "has_availability                              1.028200e-01  5  0.001835   \n",
       "host_has_profile_pic                          1.209908e-01  5  0.001128   \n",
       "calculated_host_listings_count_private_rooms  3.824028e-01  5  0.003982   \n",
       "last_scraped                                  2.338024e-01  5  0.001310   \n",
       "host_is_superhost                             2.764447e-01  5  0.001576   \n",
       "beds                                          4.350081e-01  5  0.003548   \n",
       "picture_url                                   5.000000e-01  5  0.000000   \n",
       "calculated_host_listings_count_shared_rooms   5.000000e-01  5  0.000471   \n",
       "maximum_maximum_nights                        6.255658e-01  5  0.000804   \n",
       "location                                      5.925490e-01  5  0.001128   \n",
       "number_of_reviews                             5.837922e-01  5  0.003766   \n",
       "host_total_listings_count                     6.015353e-01  5  0.003058   \n",
       "maximum_nights_avg_ntm                        6.368094e-01  5  0.002917   \n",
       "calculated_host_listings_count                8.822518e-01  5  0.000894   \n",
       "minimum_maximum_nights                        9.611292e-01  5  0.000493   \n",
       "instant_bookable                              8.312491e-01  5  0.001673   \n",
       "maximum_nights                                9.675070e-01  5  0.000693   \n",
       "\n",
       "                                               p99_low  \n",
       "amenities                                     0.033441  \n",
       "bathrooms_text                                0.033056  \n",
       "neighbourhood_cleansed                        0.037010  \n",
       "property_type                                 0.024043  \n",
       "description                                   0.022471  \n",
       "name                                          0.019038  \n",
       "host_name                                     0.004296  \n",
       "accommodates                                  0.004437  \n",
       "host_since                                   -0.001136  \n",
       "availability_30                               0.000446  \n",
       "number_of_reviews_l30d                       -0.000321  \n",
       "number_of_reviews_ltm                        -0.002406  \n",
       "minimum_minimum_nights                       -0.000183  \n",
       "availability_60                              -0.000634  \n",
       "minimum_nights                               -0.001891  \n",
       "neighbourhood_group_cleansed                 -0.002409  \n",
       "room_type                                     0.000128  \n",
       "maximum_minimum_nights                       -0.003165  \n",
       "availability_90                              -0.001413  \n",
       "host_id                                      -0.002136  \n",
       "host_verifications                           -0.001124  \n",
       "minimum_nights_avg_ntm                       -0.004854  \n",
       "calculated_host_listings_count_entire_homes  -0.002155  \n",
       "host_identity_verified                       -0.001896  \n",
       "host_listings_count                          -0.001735  \n",
       "availability_365                             -0.003507  \n",
       "has_availability                             -0.000929  \n",
       "host_has_profile_pic                         -0.000610  \n",
       "calculated_host_listings_count_private_rooms -0.003464  \n",
       "last_scraped                                 -0.000921  \n",
       "host_is_superhost                            -0.001188  \n",
       "beds                                         -0.003289  \n",
       "picture_url                                   0.000000  \n",
       "calculated_host_listings_count_shared_rooms  -0.000471  \n",
       "maximum_maximum_nights                       -0.000934  \n",
       "location                                     -0.001257  \n",
       "number_of_reviews                            -0.004155  \n",
       "host_total_listings_count                    -0.003446  \n",
       "maximum_nights_avg_ntm                       -0.003435  \n",
       "calculated_host_listings_count               -0.001671  \n",
       "minimum_maximum_nights                       -0.001529  \n",
       "instant_bookable                             -0.002709  \n",
       "maximum_nights                               -0.002376  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.feature_importance(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/46/46qfn8750nz4wpqzldyf5qf40000gn/T/ipykernel_25130/2234617067.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'predictor' is not defined"
     ]
    }
   ],
   "source": [
    "predictor.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
